"""
åœ°åŒºåˆ†ææ¨¡å—
æ”¯æŒæŒ‰åŸå¸‚/åœ°åŒºç­›é€‰å†…å®¹ï¼Œè¿›è¡Œåœ°åŒºçƒ­é—¨è¯é¢˜ç»Ÿè®¡å’Œå¯¹æ¯”
"""
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict, field
from datetime import datetime
from enum import Enum

from scraper import RedBookScraper, posts_to_dict


class City(str, Enum):
    """æ”¯æŒçš„åŸå¸‚"""
    BEIJING = "åŒ—äº¬"
    SHANGHAI = "ä¸Šæµ·"
    GUANGZHOU = "å¹¿å·"
    SHENZHEN = "æ·±åœ³"
    HANGZHOU = "æ­å·"
    CHENGDU = "æˆéƒ½"
    CHONGQING = "é‡åº†"
    NANJING = "å—äº¬"
    WUHAN = "æ­¦æ±‰"
    XIAN = "è¥¿å®‰"
    SUZHOU = "è‹å·"
    CHANGSHA = "é•¿æ²™"
    XIAMEN = "å¦é—¨"
    QINGDAO = "é’å²›"
    SANYA = "ä¸‰äºš"
    LIJIANG = "ä¸½æ±Ÿ"
    DALI = "å¤§ç†"


# åŸå¸‚é…ç½®ä¿¡æ¯
CITY_CONFIG = {
    City.BEIJING: {
        "name": "åŒ—äº¬",
        "aliases": ["åŒ—äº¬å¸‚", "å¸éƒ½", "BJ"],
        "emoji": "ğŸ›ï¸",
        "hot_topics": ["æ•…å®«", "ä¸‰é‡Œå±¯", "åæµ·", "798", "ç¯çƒå½±åŸ"],
        "specialties": ["çƒ¤é¸­", "ç‚¸é…±é¢", "è±†æ±å„¿", "å¤ç…®"]
    },
    City.SHANGHAI: {
        "name": "ä¸Šæµ·",
        "aliases": ["ä¸Šæµ·å¸‚", "é­”éƒ½", "SH"],
        "emoji": "ğŸŒƒ",
        "hot_topics": ["å¤–æ»©", "è¿ªå£«å°¼", "æ­¦åº·è·¯", "é™å®‰å¯º", "å—äº¬è·¯"],
        "specialties": ["å°ç¬¼åŒ…", "ç”Ÿç…", "æœ¬å¸®èœ", "å’–å•¡"]
    },
    City.GUANGZHOU: {
        "name": "å¹¿å·",
        "aliases": ["å¹¿å·å¸‚", "ç¾ŠåŸ", "GZ"],
        "emoji": "ğŸŒº",
        "hot_topics": ["åŒ—äº¬è·¯", "æ²™é¢", "ç æ±Ÿå¤œæ¸¸", "é•¿éš†"],
        "specialties": ["æ—©èŒ¶", "è‚ ç²‰", "çƒ§è…Š", "ç³–æ°´"]
    },
    City.SHENZHEN: {
        "name": "æ·±åœ³",
        "aliases": ["æ·±åœ³å¸‚", "é¹åŸ", "SZ"],
        "emoji": "ğŸ™ï¸",
        "hot_topics": ["åå¼ºåŒ—", "ä¸–ç•Œä¹‹çª—", "å¤§æ¢…æ²™", "æ·±åœ³æ¹¾"],
        "specialties": ["æ½®æ±•ç¾é£Ÿ", "æµ·é²œ", "èŒ¶é¥®"]
    },
    City.HANGZHOU: {
        "name": "æ­å·",
        "aliases": ["æ­å·å¸‚", "æ­åŸ"],
        "emoji": "ğŸŒŠ",
        "hot_topics": ["è¥¿æ¹–", "çµéšå¯º", "è¥¿æºªæ¹¿åœ°", "æ²³åŠè¡—"],
        "specialties": ["é¾™äº•èŒ¶", "ä¸œå¡è‚‰", "è¥¿æ¹–é†‹é±¼", "å«èŠ±é¸¡"]
    },
    City.CHENGDU: {
        "name": "æˆéƒ½",
        "aliases": ["æˆéƒ½å¸‚", "è“‰åŸ"],
        "emoji": "ğŸ¼",
        "hot_topics": ["æ˜¥ç†™è·¯", "å®½çª„å··å­", "å¤§ç†ŠçŒ«åŸºåœ°", "é”¦é‡Œ"],
        "specialties": ["ç«é”…", "ä¸²ä¸²", "æ‹…æ‹…é¢", "å…”å¤´"]
    },
    City.CHONGQING: {
        "name": "é‡åº†",
        "aliases": ["é‡åº†å¸‚", "å±±åŸ"],
        "emoji": "ğŸŒ‰",
        "hot_topics": ["æ´ªå´–æ´", "è§£æ”¾ç¢‘", "ç£å™¨å£", "é•¿æ±Ÿç´¢é“"],
        "specialties": ["ç«é”…", "å°é¢", "é…¸è¾£ç²‰", "æ¯›è¡€æ—º"]
    },
    City.NANJING: {
        "name": "å—äº¬",
        "aliases": ["å—äº¬å¸‚", "é‡‘é™µ"],
        "emoji": "ğŸ¯",
        "hot_topics": ["å¤«å­åº™", "ç„æ­¦æ¹–", "ä¸­å±±é™µ", "è€é—¨ä¸œ"],
        "specialties": ["ç›æ°´é¸­", "é¸­è¡€ç²‰ä¸æ±¤", "å°ç¬¼åŒ…"]
    },
    City.WUHAN: {
        "name": "æ­¦æ±‰",
        "aliases": ["æ­¦æ±‰å¸‚", "æ±ŸåŸ"],
        "emoji": "ğŸŒ¸",
        "hot_topics": ["é»„é¹¤æ¥¼", "æˆ·éƒ¨å··", "ä¸œæ¹–", "å…‰è°·"],
        "specialties": ["çƒ­å¹²é¢", "è±†çš®", "æ­¦æ˜Œé±¼", "ç²¾æ­¦é¸­è„–"]
    },
    City.XIAN: {
        "name": "è¥¿å®‰",
        "aliases": ["è¥¿å®‰å¸‚", "é•¿å®‰"],
        "emoji": "ğŸ°",
        "hot_topics": ["å…µé©¬ä¿‘", "å¤§é›å¡”", "å›æ°‘è¡—", "åŸå¢™"],
        "specialties": ["è‚‰å¤¹é¦", "å‡‰çš®", "ç¾Šè‚‰æ³¡é¦", "biangbiangé¢"]
    },
    City.SUZHOU: {
        "name": "è‹å·",
        "aliases": ["è‹å·å¸‚", "å§‘è‹"],
        "emoji": "ğŸ¡",
        "hot_topics": ["æ‹™æ”¿å›­", "è™ä¸˜", "å¹³æ±Ÿè·¯", "å‘¨åº„"],
        "specialties": ["è‹å¼é¢", "èŸ¹å£³é»„", "ç³•å›¢", "é˜³æ¾„æ¹–å¤§é—¸èŸ¹"]
    },
    City.CHANGSHA: {
        "name": "é•¿æ²™",
        "aliases": ["é•¿æ²™å¸‚", "æ˜ŸåŸ"],
        "emoji": "â­",
        "hot_topics": ["æ©˜å­æ´²", "å²³éº“å±±", "å¤ªå¹³è€è¡—", "äº”ä¸€å¹¿åœº"],
        "specialties": ["è‡­è±†è…", "ç³–æ²¹ç²‘ç²‘", "å£å‘³è™¾", "èŒ¶é¢œæ‚¦è‰²"]
    },
    City.XIAMEN: {
        "name": "å¦é—¨",
        "aliases": ["å¦é—¨å¸‚", "é¹­å²›"],
        "emoji": "ğŸï¸",
        "hot_topics": ["é¼“æµªå±¿", "æ›¾ååµ", "ä¸­å±±è·¯", "ç¯å²›è·¯"],
        "specialties": ["æ²™èŒ¶é¢", "æµ·è›ç…", "åœŸç¬‹å†»", "èŠ±ç”Ÿæ±¤"]
    },
    City.QINGDAO: {
        "name": "é’å²›",
        "aliases": ["é’å²›å¸‚", "å²›åŸ"],
        "emoji": "ğŸº",
        "hot_topics": ["æ ˆæ¡¥", "å…«å¤§å…³", "å´‚å±±", "é‡‘æ²™æ»©"],
        "specialties": ["é’å²›å•¤é…’", "æµ·é²œ", "è›¤èœŠ", "é²…é±¼é¥ºå­"]
    },
    City.SANYA: {
        "name": "ä¸‰äºš",
        "aliases": ["ä¸‰äºšå¸‚"],
        "emoji": "ğŸ–ï¸",
        "hot_topics": ["äºšé¾™æ¹¾", "å¤©æ¶¯æµ·è§’", "èœˆæ”¯æ´²å²›", "å—å±±å¯º"],
        "specialties": ["æµ·é²œ", "æ¤°å­é¸¡", "æŠ±ç½—ç²‰", "æ¸…è¡¥å‡‰"]
    },
    City.LIJIANG: {
        "name": "ä¸½æ±Ÿ",
        "aliases": ["ä¸½æ±Ÿå¸‚", "ä¸½æ±Ÿå¤åŸ"],
        "emoji": "ğŸ”ï¸",
        "hot_topics": ["ä¸½æ±Ÿå¤åŸ", "ç‰é¾™é›ªå±±", "æŸæ²³å¤é•‡", "æ³¸æ²½æ¹–"],
        "specialties": ["çº³è¥¿çƒ¤è‚‰", "ä¸½æ±Ÿç²‘ç²‘", "é¸¡è±†å‡‰ç²‰"]
    },
    City.DALI: {
        "name": "å¤§ç†",
        "aliases": ["å¤§ç†å¸‚", "å¤§ç†å¤åŸ"],
        "emoji": "ğŸŒ…",
        "hot_topics": ["æ´±æµ·", "å¤§ç†å¤åŸ", "åŒå»Š", "è‹å±±"],
        "specialties": ["ä¹³æ‰‡", "é¥µä¸", "ç ‚é”…é±¼", "å–œæ´²ç²‘ç²‘"]
    },
}


@dataclass
class RegionalPost:
    """åœ°åŒºå¸–å­æ•°æ®"""
    city: str
    post: Dict
    relevance_score: float  # åŸå¸‚ç›¸å…³åº¦è¯„åˆ†
    topic_matches: List[str]  # åŒ¹é…çš„çƒ­é—¨è¯é¢˜


@dataclass
class CityAnalysis:
    """åŸå¸‚åˆ†æç»“æœ"""
    city: str
    city_emoji: str
    total_posts: int
    posts: List[Dict]
    hot_topics: List[Dict]  # {topic, count, engagement}
    specialties_mentioned: List[str]
    total_engagement: int
    avg_engagement: float
    top_authors: List[Dict]  # {author, posts_count, total_likes}
    generated_at: str = ""
    
    def __post_init__(self):
        if not self.generated_at:
            self.generated_at = datetime.now().isoformat()


@dataclass 
class RegionalComparison:
    """åœ°åŒºå¯¹æ¯”ç»“æœ"""
    cities: List[str]
    comparison_data: List[Dict]  # å„åŸå¸‚çš„å¯¹æ¯”æ•°æ®
    winner: str  # çƒ­åº¦æœ€é«˜çš„åŸå¸‚
    insights: List[str]  # å¯¹æ¯”æ´å¯Ÿ
    generated_at: str = ""
    
    def __post_init__(self):
        if not self.generated_at:
            self.generated_at = datetime.now().isoformat()


class RegionalService:
    """åœ°åŒºåˆ†ææœåŠ¡"""
    
    def __init__(self):
        self.scraper = RedBookScraper()
    
    def _parse_engagement(self, value: str) -> int:
        """è§£æäº’åŠ¨æ•°"""
        if not value:
            return 0
        value = str(value).lower()
        if 'w' in value or 'ä¸‡' in value:
            return int(float(value.replace('w', '').replace('ä¸‡', '')) * 10000)
        if 'k' in value or 'åƒ' in value:
            return int(float(value.replace('k', '').replace('åƒ', '')) * 1000)
        try:
            return int(''.join(filter(str.isdigit, value))) or 0
        except:
            return 0
    
    def _calculate_relevance(self, post: Dict, city: City) -> tuple:
        """è®¡ç®—å¸–å­ä¸åŸå¸‚çš„ç›¸å…³åº¦"""
        config = CITY_CONFIG.get(city, {})
        title = post.get('title', '').lower()
        content = post.get('content', '').lower()
        text = title + " " + content
        
        score = 0
        matched_topics = []
        
        # æ£€æŸ¥åŸå¸‚å
        city_name = config.get('name', '')
        if city_name.lower() in text:
            score += 10
        
        # æ£€æŸ¥åˆ«å
        for alias in config.get('aliases', []):
            if alias.lower() in text:
                score += 5
        
        # æ£€æŸ¥çƒ­é—¨è¯é¢˜
        for topic in config.get('hot_topics', []):
            if topic.lower() in text:
                score += 3
                matched_topics.append(topic)
        
        # æ£€æŸ¥ç‰¹è‰²ç¾é£Ÿ
        for specialty in config.get('specialties', []):
            if specialty.lower() in text:
                score += 2
                matched_topics.append(specialty)
        
        return score, matched_topics
    
    async def analyze_city(
        self, 
        city: City,
        topic: Optional[str] = None,
        max_posts: int = 10
    ) -> CityAnalysis:
        """åˆ†ææŒ‡å®šåŸå¸‚çš„å†…å®¹"""
        config = CITY_CONFIG.get(city, {})
        city_name = config.get('name', city.value)
        
        # æ„å»ºæœç´¢å…³é”®è¯
        search_keywords = []
        if topic:
            search_keywords.append(f"{city_name}{topic}")
            search_keywords.append(f"{city_name} {topic}")
        else:
            search_keywords.append(f"{city_name}æ¢åº—")
            search_keywords.append(f"{city_name}æ”»ç•¥")
            search_keywords.append(f"{city_name}æ—…æ¸¸")
        
        # æŠ“å–å¸–å­
        all_posts = []
        for keyword in search_keywords[:2]:
            posts = await self.scraper.search_posts(keyword, max_posts=max_posts)
            all_posts.extend(posts_to_dict(posts))
            await asyncio.sleep(1)
        
        # å»é‡
        seen = set()
        unique_posts = []
        for post in all_posts:
            title = post.get('title', '')[:30]
            if title not in seen:
                seen.add(title)
                unique_posts.append(post)
        
        # åˆ†æçƒ­é—¨è¯é¢˜
        topic_counts = {}
        specialties_found = []
        
        for post in unique_posts:
            text = (post.get('title', '') + post.get('content', '')).lower()
            
            # ç»Ÿè®¡çƒ­é—¨è¯é¢˜
            for topic_name in config.get('hot_topics', []):
                if topic_name.lower() in text:
                    if topic_name not in topic_counts:
                        topic_counts[topic_name] = {'count': 0, 'engagement': 0}
                    topic_counts[topic_name]['count'] += 1
                    engagement = self._parse_engagement(post.get('likes', '0'))
                    topic_counts[topic_name]['engagement'] += engagement
            
            # ç»Ÿè®¡ç‰¹è‰²ç¾é£Ÿ
            for specialty in config.get('specialties', []):
                if specialty.lower() in text and specialty not in specialties_found:
                    specialties_found.append(specialty)
        
        # æ’åºçƒ­é—¨è¯é¢˜
        hot_topics = [
            {'topic': topic, 'count': data['count'], 'engagement': data['engagement']}
            for topic, data in topic_counts.items()
        ]
        hot_topics.sort(key=lambda x: x['engagement'], reverse=True)
        
        # ç»Ÿè®¡ä½œè€…
        author_stats = {}
        for post in unique_posts:
            author = post.get('author', 'æœªçŸ¥')
            if author not in author_stats:
                author_stats[author] = {'posts_count': 0, 'total_likes': 0}
            author_stats[author]['posts_count'] += 1
            author_stats[author]['total_likes'] += self._parse_engagement(post.get('likes', '0'))
        
        top_authors = [
            {'author': author, **stats}
            for author, stats in sorted(
                author_stats.items(), 
                key=lambda x: x[1]['total_likes'], 
                reverse=True
            )[:5]
        ]
        
        # è®¡ç®—æ€»äº’åŠ¨
        total_engagement = sum(
            self._parse_engagement(p.get('likes', '0')) + 
            self._parse_engagement(p.get('comments', '0'))
            for p in unique_posts
        )
        avg_engagement = total_engagement / len(unique_posts) if unique_posts else 0
        
        return CityAnalysis(
            city=city_name,
            city_emoji=config.get('emoji', 'ğŸ“'),
            total_posts=len(unique_posts),
            posts=unique_posts[:max_posts],
            hot_topics=hot_topics[:10],
            specialties_mentioned=specialties_found,
            total_engagement=total_engagement,
            avg_engagement=round(avg_engagement, 2),
            top_authors=top_authors
        )
    
    async def compare_cities(
        self,
        cities: List[City],
        topic: Optional[str] = None
    ) -> RegionalComparison:
        """å¯¹æ¯”å¤šä¸ªåŸå¸‚"""
        comparison_data = []
        
        for city in cities:
            analysis = await self.analyze_city(city, topic, max_posts=5)
            config = CITY_CONFIG.get(city, {})
            
            comparison_data.append({
                'city': analysis.city,
                'emoji': config.get('emoji', 'ğŸ“'),
                'total_posts': analysis.total_posts,
                'total_engagement': analysis.total_engagement,
                'avg_engagement': analysis.avg_engagement,
                'top_topics': [t['topic'] for t in analysis.hot_topics[:3]],
                'specialties': analysis.specialties_mentioned[:3]
            })
            await asyncio.sleep(1)
        
        # æ‰¾å‡ºçƒ­åº¦æœ€é«˜çš„åŸå¸‚
        comparison_data.sort(key=lambda x: x['total_engagement'], reverse=True)
        winner = comparison_data[0]['city'] if comparison_data else ""
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = []
        if len(comparison_data) >= 2:
            insights.append(f"ğŸ† {winner} åœ¨è¯¥è¯é¢˜ä¸Šçƒ­åº¦æœ€é«˜ï¼Œæ€»äº’åŠ¨é‡è¾¾ {comparison_data[0]['total_engagement']}")
            
            if comparison_data[0]['avg_engagement'] > comparison_data[-1]['avg_engagement'] * 2:
                insights.append(f"ğŸ“Š {comparison_data[0]['city']} çš„å¹³å‡äº’åŠ¨é‡æ˜¯ {comparison_data[-1]['city']} çš„ {round(comparison_data[0]['avg_engagement']/max(comparison_data[-1]['avg_engagement'], 1), 1)} å€")
            
            all_topics = set()
            for data in comparison_data:
                all_topics.update(data['top_topics'])
            if all_topics:
                insights.append(f"ğŸ”¥ çƒ­é—¨è¯é¢˜åŒ…æ‹¬ï¼š{', '.join(list(all_topics)[:5])}")
        
        return RegionalComparison(
            cities=[c.value for c in cities],
            comparison_data=comparison_data,
            winner=winner,
            insights=insights
        )
    
    async def get_trending_cities(self, topic: str, max_cities: int = 5) -> List[Dict]:
        """è·å–æŸè¯é¢˜ä¸‹çƒ­é—¨åŸå¸‚æ’å"""
        city_scores = []
        
        # é‡‡æ ·éƒ¨åˆ†çƒ­é—¨åŸå¸‚
        sample_cities = [
            City.SHANGHAI, City.BEIJING, City.HANGZHOU, 
            City.CHENGDU, City.SHENZHEN, City.GUANGZHOU,
            City.CHONGQING, City.XIAMEN, City.SANYA
        ]
        
        for city in sample_cities[:6]:
            config = CITY_CONFIG.get(city, {})
            keyword = f"{config.get('name', '')} {topic}"
            
            posts = await self.scraper.search_posts(keyword, max_posts=3)
            posts_dict = posts_to_dict(posts)
            
            total_engagement = sum(
                self._parse_engagement(p.get('likes', '0'))
                for p in posts_dict
            )
            
            city_scores.append({
                'city': config.get('name', city.value),
                'emoji': config.get('emoji', 'ğŸ“'),
                'posts_count': len(posts_dict),
                'total_engagement': total_engagement,
                'sample_posts': [p.get('title', '')[:30] for p in posts_dict[:2]]
            })
            
            await asyncio.sleep(0.5)
        
        # æ’åº
        city_scores.sort(key=lambda x: x['total_engagement'], reverse=True)
        
        return city_scores[:max_cities]


def city_analysis_to_dict(analysis: CityAnalysis) -> Dict:
    """è½¬æ¢åŸå¸‚åˆ†æç»“æœä¸ºå­—å…¸"""
    return asdict(analysis)


async def main():
    """æµ‹è¯•åœ°åŒºåˆ†æåŠŸèƒ½"""
    service = RegionalService()
    
    print("ğŸ™ï¸ åˆ†æä¸Šæµ·ç¾é£Ÿæ¢åº—...")
    analysis = await service.analyze_city(City.SHANGHAI, topic="ç¾é£Ÿ")
    
    print(f"\n{analysis.city_emoji} {analysis.city}")
    print(f"å¸–å­æ•°: {analysis.total_posts}")
    print(f"æ€»äº’åŠ¨: {analysis.total_engagement}")
    print(f"å¹³å‡äº’åŠ¨: {analysis.avg_engagement}")
    
    print("\nğŸ”¥ çƒ­é—¨è¯é¢˜:")
    for topic in analysis.hot_topics[:5]:
        print(f"  â€¢ {topic['topic']}: {topic['count']}ç¯‡, {topic['engagement']}äº’åŠ¨")
    
    print("\nğŸœ æåŠçš„ç‰¹è‰²ç¾é£Ÿ:")
    print(f"  {', '.join(analysis.specialties_mentioned)}")


if __name__ == "__main__":
    asyncio.run(main())

